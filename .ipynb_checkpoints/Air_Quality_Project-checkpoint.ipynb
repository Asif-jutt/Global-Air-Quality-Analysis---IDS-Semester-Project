{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d15a396",
   "metadata": {},
   "source": [
    "# Global Air Quality Analysis - CSC380 Semester Project\n",
    "**University of Engineering and Technology, Lahore | Fall 2025**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760dd38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries and Create Output Folders\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             confusion_matrix, classification_report,\n",
    "                             mean_absolute_error, mean_squared_error, r2_score)\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create folders for saving graphs\n",
    "folders = ['graphs/1_preprocessing', 'graphs/2_eda_univariate', 'graphs/3_eda_bivariate', \n",
    "           'graphs/4_correlation', 'graphs/5_comparative', 'graphs/6_timeseries', 'graphs/7_models']\n",
    "for folder in folders:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "print(\"‚úÖ Libraries imported and folders created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40985f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv('global_air_quality_dataset.csv')\n",
    "df_original = df.copy()\n",
    "\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac0b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Info and Statistics\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nStatistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e8d0cd",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8076f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Check and Handle Missing Values\n",
    "print(\"Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Visualize missing values\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "df.isnull().sum().plot(kind='bar', color=['red' if x > 0 else 'green' for x in df.isnull().sum()])\n",
    "plt.title('Missing Values by Column')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/1_preprocessing/missing_values.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Impute missing values\n",
    "numerical_cols = ['PM2.5', 'PM10', 'NO2', 'SO2', 'CO', 'O3', 'Temperature', 'Humidity', 'Wind Speed']\n",
    "for col in numerical_cols:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "print(\"\\n‚úÖ Missing values after imputation:\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83835ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Outlier Detection - Box Plots Before Treatment\n",
    "pollutant_cols = ['PM2.5', 'PM10', 'NO2', 'SO2', 'CO', 'O3']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "axes = axes.flatten()\n",
    "for i, col in enumerate(pollutant_cols):\n",
    "    axes[i].boxplot(df[col], patch_artist=True, boxprops=dict(facecolor='lightcoral'))\n",
    "    axes[i].set_title(f'{col} (Before)')\n",
    "    axes[i].set_ylabel('Concentration')\n",
    "plt.suptitle('Outlier Detection - Before Treatment', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/1_preprocessing/outliers_before.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da93eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Outlier Detection using IQR and Z-Score Methods\n",
    "print(\"Outlier Detection Summary:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for col in numerical_cols:\n",
    "    # IQR Method\n",
    "    Q1, Q3 = df[col].quantile(0.25), df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    iqr_outliers = ((df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)).sum()\n",
    "    \n",
    "    # Z-Score Method\n",
    "    z_outliers = (np.abs(zscore(df[col])) > 3).sum()\n",
    "    \n",
    "    print(f\"{col}: IQR Outliers={iqr_outliers}, Z-Score Outliers={z_outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c99ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 Handle Outliers using IQR Capping\n",
    "for col in numerical_cols:\n",
    "    Q1, Q3 = df[col].quantile(0.25), df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR\n",
    "    df[col] = df[col].clip(lower, upper)\n",
    "\n",
    "# Box Plots After Treatment\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "axes = axes.flatten()\n",
    "for i, col in enumerate(pollutant_cols):\n",
    "    axes[i].boxplot(df[col], patch_artist=True, boxprops=dict(facecolor='lightgreen'))\n",
    "    axes[i].set_title(f'{col} (After)')\n",
    "    axes[i].set_ylabel('Concentration')\n",
    "plt.suptitle('Outlier Treatment - After Capping', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/1_preprocessing/outliers_after.png', dpi=150)\n",
    "plt.show()\n",
    "print(\"‚úÖ Outliers handled using IQR capping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d5fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5 Calculate AQI and Create Categories\n",
    "pm25_bp = [(0, 12, 0, 50), (12.1, 35.4, 51, 100), (35.5, 55.4, 101, 150),\n",
    "           (55.5, 150.4, 151, 200), (150.5, 250.4, 201, 300), (250.5, 500, 301, 500)]\n",
    "\n",
    "def calc_aqi(pm25):\n",
    "    for low, high, aqi_low, aqi_high in pm25_bp:\n",
    "        if low <= pm25 <= high:\n",
    "            return ((aqi_high - aqi_low) / (high - low)) * (pm25 - low) + aqi_low\n",
    "    return 500\n",
    "\n",
    "df['AQI'] = df['PM2.5'].apply(calc_aqi)\n",
    "\n",
    "# Categorize AQI\n",
    "def aqi_category(aqi):\n",
    "    if aqi <= 50: return 'Good'\n",
    "    elif aqi <= 100: return 'Moderate'\n",
    "    elif aqi <= 150: return 'Unhealthy'\n",
    "    else: return 'Hazardous'\n",
    "\n",
    "df['AQI_Category'] = df['AQI'].apply(aqi_category)\n",
    "df['AQI_Encoded'] = df['AQI_Category'].map({'Good': 0, 'Moderate': 1, 'Unhealthy': 2, 'Hazardous': 3})\n",
    "\n",
    "# Visualize AQI Distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].hist(df['AQI'], bins=50, color='steelblue', edgecolor='black')\n",
    "axes[0].set_title('AQI Distribution')\n",
    "axes[0].set_xlabel('AQI')\n",
    "\n",
    "colors = ['green', 'yellow', 'orange', 'red']\n",
    "df['AQI_Category'].value_counts().reindex(['Good', 'Moderate', 'Unhealthy', 'Hazardous']).plot(\n",
    "    kind='bar', ax=axes[1], color=colors)\n",
    "axes[1].set_title('AQI Categories')\n",
    "axes[1].set_ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/1_preprocessing/aqi_distribution.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"AQI Category Distribution:\")\n",
    "print(df['AQI_Category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339a55e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.6 Feature Scaling - Standardization and Normalization\n",
    "features = ['PM2.5', 'PM10', 'NO2', 'SO2', 'CO', 'O3', 'Temperature', 'Humidity', 'Wind Speed']\n",
    "\n",
    "# Compare scaling methods\n",
    "scaler_std = StandardScaler()\n",
    "scaler_mm = MinMaxScaler()\n",
    "\n",
    "df_std = df.copy()\n",
    "df_norm = df.copy()\n",
    "df_std[features] = scaler_std.fit_transform(df[features])\n",
    "df_norm[features] = scaler_mm.fit_transform(df[features])\n",
    "\n",
    "# Visualize scaling comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "axes[0].hist(df['PM2.5'], bins=40, color='red', alpha=0.7)\n",
    "axes[0].set_title('Original PM2.5')\n",
    "axes[1].hist(df_std['PM2.5'], bins=40, color='blue', alpha=0.7)\n",
    "axes[1].set_title('Standardized (Z-score)')\n",
    "axes[2].hist(df_norm['PM2.5'], bins=40, color='green', alpha=0.7)\n",
    "axes[2].set_title('Normalized (Min-Max)')\n",
    "plt.suptitle('Feature Scaling Comparison', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/1_preprocessing/scaling_comparison.png', dpi=150)\n",
    "plt.show()\n",
    "print(\"‚úÖ Feature scaling applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b134c952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.7 Train-Test Split (80-20)\n",
    "X = df[features]\n",
    "y = df['AQI_Encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples ({len(X_train)/len(X)*100:.0f}%)\")\n",
    "print(f\"Test set: {len(X_test)} samples ({len(X_test)/len(X)*100:.0f}%)\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(pd.Series(y_train).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fbe06a",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c86271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Univariate Analysis - Pollutant Distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "axes = axes.flatten()\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6', '#1abc9c']\n",
    "\n",
    "for i, (col, color) in enumerate(zip(pollutant_cols, colors)):\n",
    "    axes[i].hist(df[col], bins=40, color=color, alpha=0.7, edgecolor='black', density=True)\n",
    "    df[col].plot(kind='kde', ax=axes[i], color='black', linewidth=2)\n",
    "    axes[i].axvline(df[col].mean(), color='red', linestyle='--', label=f'Mean: {df[col].mean():.1f}')\n",
    "    axes[i].set_title(f'{col} Distribution')\n",
    "    axes[i].legend()\n",
    "plt.suptitle('Univariate Analysis - Pollutant Distributions', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/2_eda_univariate/pollutant_distributions.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be09d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1b Univariate Analysis - Weather Variables\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "weather_cols = ['Temperature', 'Humidity', 'Wind Speed']\n",
    "weather_colors = ['#e74c3c', '#3498db', '#2ecc71']\n",
    "\n",
    "for i, (col, color) in enumerate(zip(weather_cols, weather_colors)):\n",
    "    axes[i].hist(df[col], bins=40, color=color, alpha=0.7, edgecolor='black', density=True)\n",
    "    df[col].plot(kind='kde', ax=axes[i], color='black', linewidth=2)\n",
    "    axes[i].set_title(f'{col} Distribution')\n",
    "plt.suptitle('Univariate Analysis - Weather Variables', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/2_eda_univariate/weather_distributions.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbe5830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1c Skewness and Kurtosis Analysis\n",
    "print(\"Skewness and Kurtosis Analysis:\")\n",
    "print(\"-\" * 50)\n",
    "for col in numerical_cols:\n",
    "    skew = df[col].skew()\n",
    "    kurt = df[col].kurtosis()\n",
    "    print(f\"{col}: Skewness={skew:.3f}, Kurtosis={kurt:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b930b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1d Categorical Variables Distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "df['City'].value_counts().plot(kind='barh', ax=axes[0], color=plt.cm.viridis(np.linspace(0, 1, df['City'].nunique())))\n",
    "axes[0].set_title('Records by City')\n",
    "axes[0].set_xlabel('Count')\n",
    "\n",
    "df['Country'].value_counts().plot(kind='barh', ax=axes[1], color=plt.cm.plasma(np.linspace(0, 1, df['Country'].nunique())))\n",
    "axes[1].set_title('Records by Country')\n",
    "axes[1].set_xlabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/2_eda_univariate/categorical_distribution.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e60c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Bivariate Analysis - Pollutants vs Weather\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "\n",
    "axes[0,0].scatter(df['Temperature'], df['PM2.5'], alpha=0.3, c='red', s=10)\n",
    "axes[0,0].set_xlabel('Temperature'); axes[0,0].set_ylabel('PM2.5'); axes[0,0].set_title('PM2.5 vs Temperature')\n",
    "\n",
    "axes[0,1].scatter(df['Humidity'], df['PM2.5'], alpha=0.3, c='blue', s=10)\n",
    "axes[0,1].set_xlabel('Humidity'); axes[0,1].set_ylabel('PM2.5'); axes[0,1].set_title('PM2.5 vs Humidity')\n",
    "\n",
    "axes[0,2].scatter(df['Wind Speed'], df['PM2.5'], alpha=0.3, c='green', s=10)\n",
    "axes[0,2].set_xlabel('Wind Speed'); axes[0,2].set_ylabel('PM2.5'); axes[0,2].set_title('PM2.5 vs Wind Speed')\n",
    "\n",
    "axes[1,0].scatter(df['Temperature'], df['O3'], alpha=0.3, c='orange', s=10)\n",
    "axes[1,0].set_xlabel('Temperature'); axes[1,0].set_ylabel('O3'); axes[1,0].set_title('O3 vs Temperature')\n",
    "\n",
    "axes[1,1].scatter(df['Temperature'], df['NO2'], alpha=0.3, c='purple', s=10)\n",
    "axes[1,1].set_xlabel('Temperature'); axes[1,1].set_ylabel('NO2'); axes[1,1].set_title('NO2 vs Temperature')\n",
    "\n",
    "axes[1,2].scatter(df['Wind Speed'], df['CO'], alpha=0.3, c='teal', s=10)\n",
    "axes[1,2].set_xlabel('Wind Speed'); axes[1,2].set_ylabel('CO'); axes[1,2].set_title('CO vs Wind Speed')\n",
    "\n",
    "plt.suptitle('Bivariate Analysis - Pollutants vs Weather', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/3_eda_bivariate/pollutants_vs_weather.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05acf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2b Bivariate - Pollutants by AQI Category\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "axes = axes.flatten()\n",
    "order = ['Good', 'Moderate', 'Unhealthy', 'Hazardous']\n",
    "\n",
    "for i, col in enumerate(pollutant_cols):\n",
    "    sns.boxplot(data=df, x='AQI_Category', y=col, ax=axes[i], order=order, palette='RdYlGn_r')\n",
    "    axes[i].set_title(f'{col} by AQI Category')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "plt.suptitle('Bivariate Analysis - Pollutants by AQI Category', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/3_eda_bivariate/pollutants_by_aqi.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0b808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Correlation Analysis\n",
    "corr_cols = numerical_cols + ['AQI']\n",
    "corr_matrix = df[corr_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='RdYlBu_r', \n",
    "            center=0, square=True, linewidths=0.5, vmin=-1, vmax=1)\n",
    "plt.title('Correlation Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/4_correlation/correlation_heatmap.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Strong correlations\n",
    "print(\"Strong Correlations (|r| > 0.5):\")\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.5:\n",
    "            print(f\"  {corr_matrix.columns[i]} ‚Üî {corr_matrix.columns[j]}: {corr_matrix.iloc[i, j]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b9474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Comparative Analysis - By City\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "city_aqi = df.groupby('City')['AQI'].mean().sort_values(ascending=False)\n",
    "city_aqi.plot(kind='barh', ax=axes[0,0], color=plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(city_aqi))))\n",
    "axes[0,0].set_title('Mean AQI by City'); axes[0,0].set_xlabel('AQI')\n",
    "\n",
    "city_pm25 = df.groupby('City')['PM2.5'].mean().sort_values(ascending=False)\n",
    "city_pm25.plot(kind='barh', ax=axes[0,1], color='coral')\n",
    "axes[0,1].set_title('Mean PM2.5 by City'); axes[0,1].set_xlabel('PM2.5')\n",
    "\n",
    "city_no2 = df.groupby('City')['NO2'].mean().sort_values(ascending=False)\n",
    "city_no2.plot(kind='barh', ax=axes[1,0], color='steelblue')\n",
    "axes[1,0].set_title('Mean NO2 by City'); axes[1,0].set_xlabel('NO2')\n",
    "\n",
    "city_o3 = df.groupby('City')['O3'].mean().sort_values(ascending=False)\n",
    "city_o3.plot(kind='barh', ax=axes[1,1], color='goldenrod')\n",
    "axes[1,1].set_title('Mean O3 by City'); axes[1,1].set_xlabel('O3')\n",
    "\n",
    "plt.suptitle('Comparative Analysis by City', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/5_comparative/city_comparison.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d9eb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4b Comparative Analysis - By Country\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "sns.violinplot(data=df, x='Country', y='PM2.5', ax=axes[0], palette='Set2')\n",
    "axes[0].set_title('PM2.5 Distribution by Country'); axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "sns.violinplot(data=df, x='Country', y='AQI', ax=axes[1], palette='RdYlGn_r')\n",
    "axes[1].set_title('AQI Distribution by Country'); axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.suptitle('Comparative Analysis by Country', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/5_comparative/country_comparison.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean Pollutants by Country:\")\n",
    "print(df.groupby('Country')[pollutant_cols + ['AQI']].mean().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98116687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 Time Series & Cycle Detection\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
    "df['Quarter'] = df['Date'].dt.quarter\n",
    "\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "\n",
    "# Monthly Cycle\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "monthly_aqi = df.groupby('Month')['AQI'].mean()\n",
    "axes[0,0].plot(monthly_aqi.index, monthly_aqi.values, marker='o', linewidth=2, color='red')\n",
    "axes[0,0].fill_between(monthly_aqi.index, monthly_aqi.values, alpha=0.3, color='red')\n",
    "axes[0,0].set_xticks(range(1, 13)); axes[0,0].set_xticklabels(month_names)\n",
    "axes[0,0].set_title('Monthly AQI Cycle'); axes[0,0].set_ylabel('AQI')\n",
    "\n",
    "monthly_pm25 = df.groupby('Month')['PM2.5'].mean()\n",
    "axes[0,1].plot(monthly_pm25.index, monthly_pm25.values, marker='s', linewidth=2, color='blue')\n",
    "axes[0,1].fill_between(monthly_pm25.index, monthly_pm25.values, alpha=0.3, color='blue')\n",
    "axes[0,1].set_xticks(range(1, 13)); axes[0,1].set_xticklabels(month_names)\n",
    "axes[0,1].set_title('Monthly PM2.5 Cycle'); axes[0,1].set_ylabel('PM2.5')\n",
    "\n",
    "# Weekly Cycle\n",
    "weekly_aqi = df.groupby('DayOfWeek')['AQI'].mean()\n",
    "axes[1,0].bar(weekly_aqi.index, weekly_aqi.values, color=plt.cm.viridis(np.linspace(0.2, 0.8, 7)))\n",
    "axes[1,0].set_xticks(range(7)); axes[1,0].set_xticklabels(day_names)\n",
    "axes[1,0].set_title('Weekly AQI Cycle'); axes[1,0].set_ylabel('AQI')\n",
    "\n",
    "# Seasonal Cycle\n",
    "season_map = {1: 'Winter', 2: 'Spring', 3: 'Summer', 4: 'Fall'}\n",
    "df['Season'] = df['Quarter'].map(season_map)\n",
    "seasonal_aqi = df.groupby('Season')['AQI'].mean().reindex(['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "axes[1,1].bar(seasonal_aqi.index, seasonal_aqi.values, color=['#3498db', '#2ecc71', '#f1c40f', '#e67e22'])\n",
    "axes[1,1].set_title('Seasonal AQI Cycle'); axes[1,1].set_ylabel('AQI')\n",
    "\n",
    "plt.suptitle('Time Series & Cycle Detection', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/6_timeseries/cycles.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d19da5",
   "metadata": {},
   "source": [
    "## 3. Model Building & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09abc9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation Function\n",
    "label_map = {0: 'Good', 1: 'Moderate', 2: 'Unhealthy', 3: 'Hazardous'}\n",
    "results = []\n",
    "\n",
    "def train_evaluate_model(name, model):\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    cv = cross_val_score(model, X_train_scaled, y_train, cv=5).mean()\n",
    "    \n",
    "    results.append({'Model': name, 'Accuracy': acc, 'Precision': prec, 'Recall': rec, 'F1': f1, 'CV Score': cv})\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"MODEL: {name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f}\")\n",
    "    print(f\"\\nConfusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n",
    "    \n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa55e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Logistic Regression\n",
    "lr_model, lr_pred = train_evaluate_model('Logistic Regression', LogisticRegression(max_iter=1000, random_state=42))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, lr_pred), annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=label_map.values(), yticklabels=label_map.values())\n",
    "plt.title('Logistic Regression - Confusion Matrix'); plt.xlabel('Predicted'); plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/7_models/logistic_regression_cm.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031f159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Decision Tree\n",
    "dt_model, dt_pred = train_evaluate_model('Decision Tree', DecisionTreeClassifier(max_depth=10, random_state=42))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "sns.heatmap(confusion_matrix(y_test, dt_pred), annot=True, fmt='d', cmap='Greens', ax=axes[0],\n",
    "            xticklabels=label_map.values(), yticklabels=label_map.values())\n",
    "axes[0].set_title('Decision Tree - Confusion Matrix'); axes[0].set_xlabel('Predicted'); axes[0].set_ylabel('Actual')\n",
    "\n",
    "dt_importance = pd.Series(dt_model.feature_importances_, index=features).sort_values()\n",
    "dt_importance.plot(kind='barh', ax=axes[1], color='forestgreen')\n",
    "axes[1].set_title('Decision Tree - Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/7_models/decision_tree.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ffde67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Random Forest\n",
    "rf_model, rf_pred = train_evaluate_model('Random Forest', RandomForestClassifier(n_estimators=100, max_depth=15, random_state=42))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "sns.heatmap(confusion_matrix(y_test, rf_pred), annot=True, fmt='d', cmap='YlGn', ax=axes[0],\n",
    "            xticklabels=label_map.values(), yticklabels=label_map.values())\n",
    "axes[0].set_title('Random Forest - Confusion Matrix'); axes[0].set_xlabel('Predicted'); axes[0].set_ylabel('Actual')\n",
    "\n",
    "rf_importance = pd.Series(rf_model.feature_importances_, index=features).sort_values()\n",
    "rf_importance.plot(kind='barh', ax=axes[1], color='darkgreen')\n",
    "axes[1].set_title('Random Forest - Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/7_models/random_forest.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3bd20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: Support Vector Machine (SVM)\n",
    "svm_model, svm_pred = train_evaluate_model('SVM (RBF)', SVC(kernel='rbf', random_state=42))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, svm_pred), annot=True, fmt='d', cmap='Purples',\n",
    "            xticklabels=label_map.values(), yticklabels=label_map.values())\n",
    "plt.title('SVM - Confusion Matrix'); plt.xlabel('Predicted'); plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/7_models/svm_cm.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93422c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5: K-Nearest Neighbors (KNN) with Elbow Method\n",
    "k_scores = []\n",
    "for k in range(1, 21):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    cv_score = cross_val_score(knn, X_train_scaled, y_train, cv=5).mean()\n",
    "    k_scores.append(cv_score)\n",
    "\n",
    "optimal_k = np.argmax(k_scores) + 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(range(1, 21), k_scores, marker='o', linewidth=2)\n",
    "ax.axvline(optimal_k, color='red', linestyle='--', label=f'Optimal K={optimal_k}')\n",
    "ax.set_xlabel('K'); ax.set_ylabel('CV Accuracy'); ax.set_title('KNN - Elbow Method')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/7_models/knn_elbow.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "knn_model, knn_pred = train_evaluate_model(f'KNN (K={optimal_k})', KNeighborsClassifier(n_neighbors=optimal_k))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, knn_pred), annot=True, fmt='d', cmap='Oranges',\n",
    "            xticklabels=label_map.values(), yticklabels=label_map.values())\n",
    "plt.title('KNN - Confusion Matrix'); plt.xlabel('Predicted'); plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/7_models/knn_cm.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7e61be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Comparison\n",
    "results_df = pd.DataFrame(model_results).T\n",
    "results_df.columns = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'CV Mean', 'CV Std']\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.round(4).to_string())\n",
    "print(\"\\nBest Model:\", results_df['F1-Score'].idxmax(), f\"(F1: {results_df['F1-Score'].max():.4f})\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "results_df[['Accuracy', 'Precision', 'Recall', 'F1-Score']].plot(kind='bar', ax=axes[0], colormap='viridis')\n",
    "axes[0].set_title('Model Performance Metrics'); axes[0].set_ylabel('Score')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45, ha='right')\n",
    "axes[0].legend(loc='lower right'); axes[0].set_ylim(0, 1.1)\n",
    "\n",
    "results_df['CV Mean'].plot(kind='bar', ax=axes[1], color='steelblue', yerr=results_df['CV Std'], capsize=5)\n",
    "axes[1].set_title('Cross-Validation Scores'); axes[1].set_ylabel('CV Accuracy')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45, ha='right')\n",
    "axes[1].set_ylim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/7_models/model_comparison.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eaff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance (from Random Forest)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.barh(feature_importance['Feature'], feature_importance['Importance'], color='forestgreen')\n",
    "ax.set_xlabel('Importance'); ax.set_title('Random Forest - Feature Importance')\n",
    "for i, v in enumerate(feature_importance['Importance']):\n",
    "    ax.text(v + 0.01, i, f'{v:.3f}', va='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/7_models/feature_importance.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "print(feature_importance.tail().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea211df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Health Impact Analysis - WHO Guidelines Comparison\n",
    "who_guidelines = {'PM2.5': 15, 'PM10': 45, 'NO2': 25, 'SO2': 40, 'O3': 100, 'CO': 4}\n",
    "actual_means = df[list(who_guidelines.keys())].mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(who_guidelines))\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, actual_means.values, width, label='Dataset Mean', color='coral')\n",
    "ax.bar(x + width/2, list(who_guidelines.values()), width, label='WHO Guideline', color='seagreen')\n",
    "ax.set_xticks(x); ax.set_xticklabels(who_guidelines.keys())\n",
    "ax.set_ylabel('Concentration'); ax.set_title('Pollutant Levels vs WHO Guidelines')\n",
    "ax.legend()\n",
    "for i, (v1, v2) in enumerate(zip(actual_means.values, who_guidelines.values())):\n",
    "    status = '‚ö†Ô∏è' if v1 > v2 else '‚úì'\n",
    "    ax.annotate(status, (i, max(v1, v2) + 2), ha='center', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/5_comparative/who_comparison.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nHealth Risk Assessment:\")\n",
    "for pollutant, who_val in who_guidelines.items():\n",
    "    actual = actual_means[pollutant]\n",
    "    pct = ((actual - who_val) / who_val) * 100\n",
    "    status = \"EXCEEDS\" if actual > who_val else \"WITHIN\"\n",
    "    print(f\"  {pollutant}: {actual:.2f} ({status} WHO limit by {abs(pct):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec27e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AQI Category Distribution by Region\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "aqi_by_country = df.groupby(['Country', 'AQI_Category']).size().unstack(fill_value=0)\n",
    "aqi_by_country = aqi_by_country.div(aqi_by_country.sum(axis=1), axis=0) * 100\n",
    "aqi_by_country.plot(kind='bar', stacked=True, ax=ax, \n",
    "                    color=['green', 'gold', 'orange', 'red', 'purple', 'maroon'])\n",
    "ax.set_ylabel('Percentage (%)'); ax.set_title('AQI Category Distribution by Country')\n",
    "ax.legend(title='AQI Category', bbox_to_anchor=(1.02, 1))\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/5_comparative/aqi_by_country.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2dcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics and Key Findings\n",
    "print(\"=\" * 80)\n",
    "print(\"PROJECT SUMMARY: GLOBAL AIR QUALITY ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nDataset: {len(df)} records from {df['Country'].nunique()} countries, {df['City'].nunique()} cities\")\n",
    "print(f\"\\nAQI Distribution:\")\n",
    "for cat in df['AQI_Category'].value_counts().index:\n",
    "    pct = (df['AQI_Category'] == cat).sum() / len(df) * 100\n",
    "    print(f\"  {cat}: {pct:.1f}%\")\n",
    "\n",
    "print(f\"\\nBest Performing Model: {results_df['F1-Score'].idxmax()}\")\n",
    "print(f\"  - F1-Score: {results_df['F1-Score'].max():.4f}\")\n",
    "print(f\"  - Accuracy: {results_df.loc[results_df['F1-Score'].idxmax(), 'Accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\nTop 3 Important Features:\")\n",
    "for _, row in feature_importance.tail(3).iterrows():\n",
    "    print(f\"  - {row['Feature']}: {row['Importance']:.4f}\")\n",
    "\n",
    "print(\"\\nKey Recommendations:\")\n",
    "print(\"  1. Focus monitoring on PM2.5 and PM10 as primary health risk indicators\")\n",
    "print(\"  2. Implement targeted interventions in regions with 'Unhealthy' or worse AQI\")\n",
    "print(\"  3. Use ML models for real-time AQI prediction and early warning systems\")\n",
    "print(\"  4. Weather conditions (temp, humidity) significantly influence pollutant levels\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df51ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Final Results to CSV\n",
    "results_df.to_csv('model_results.csv')\n",
    "feature_importance.to_csv('feature_importance.csv', index=False)\n",
    "print(\"Results saved to CSV files!\")\n",
    "print(f\"\\nAll graphs saved to organized folders:\")\n",
    "for folder in sorted(os.listdir('graphs')):\n",
    "    files = os.listdir(f'graphs/{folder}')\n",
    "    print(f\"  üìÅ graphs/{folder}/ ({len(files)} files)\")\n",
    "    for f in files:\n",
    "        print(f\"      ‚îî‚îÄ‚îÄ {f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
